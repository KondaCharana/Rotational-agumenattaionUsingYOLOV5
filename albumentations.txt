import albumentations as A
from albumentations.pytorch import ToTensorV2
import torch
import cv2
import os
from torch.utils.data import DataLoader
import json

# Step 1: Define the data augmentation pipeline
augmentation_pipeline = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomRotation(10),
    A.RandomResizedCrop(width=640, height=640, scale=(0.8, 1.0)),
    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, p=0.5),
    ToTensorV2()
], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))

# Step 2: Create output directories for images and labels
augmented_image_dir = "augmented_images"
augmented_label_dir = "augmented_labels"

os.makedirs(augmented_image_dir, exist_ok=True)
os.makedirs(augmented_label_dir, exist_ok=True)

# Step 3: Create a custom dataset class for object detection with augmentation and saving
class CustomObjectDetectionDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, label_dir, transform=None, save_augmented=False):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])
        self.transform = transform
        self.save_augmented = save_augmented
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # Get image and label paths
        image_file = self.image_files[idx]
        img_path = os.path.join(self.image_dir, image_file)
        label_path = os.path.join(self.label_dir, image_file.replace('.jpg', '.txt'))

        # Load image
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Read bounding box information from the .txt file
        with open(label_path, 'r') as f:
            lines = f.readlines()

        img_height, img_width, _ = image.shape
        boxes = []
        labels = []
        
        for line in lines:
            values = line.strip().split()  # Split line into components
            label = int(values[0])  # Class label
            center_x, center_y, width, height = map(float, values[1:])
            
            # Convert from normalized YOLO coordinates to absolute coordinates
            x1 = (center_x - width / 2) * img_width
            y1 = (center_y - height / 2) * img_height
            x2 = (center_x + width / 2) * img_width
            y2 = (center_y + height / 2) * img_height
            
            boxes.append([x1, y1, x2, y2])
            labels.append(label)
        
        # Apply data augmentation if specified
        if self.transform:
            augmented = self.transform(image=image, bboxes=boxes, labels=labels)
            image = augmented['image']
            boxes = augmented['bboxes']
            labels = augmented['labels']
        
        # Save the augmented image and updated labels if required
        if self.save_augmented:
            # Save the augmented image
            save_path = os.path.join(augmented_image_dir, f"augmented_{image_file}")
            cv2.imwrite(save_path, cv2.cvtColor(image.cpu().numpy().transpose(1, 2, 0), cv2.COLOR_RGB2BGR))
            
            # Save the augmented labels in YOLO format
            augmented_label_path = os.path.join(augmented_label_dir, f"augmented_{image_file.replace('.jpg', '.txt')}")
            with open(augmented_label_path, 'w') as f:
                for i, box in enumerate(boxes):
                    # Convert back to normalized YOLO coordinates
                    center_x = ((box[0] + box[2]) / 2) / img_width
                    center_y = ((box[1] + box[3]) / 2) / img_height
                    width = (box[2] - box[0]) / img_width
                    height = (box[3] - box[1]) / img_height
                    f.write(f"{labels[i]} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")

        return {
            'image': image,
            'boxes': boxes,
            'labels': labels
        }

# Step 4: Create and load the dataset with augmentation and saving enabled
image_dir = "path/to/your/images"
label_dir = "path/to/your/labels"

train_dataset = CustomObjectDetectionDataset(
    image_dir=image_dir,
    label_dir=label_dir,
    transform=augmentation_pipeline,
    save_augmented=True
)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Use this train_loader to train your YOLOv5 model or process the augmented data as needed
